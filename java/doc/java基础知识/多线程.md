# JVM内存结构

![](.\png\java内存区域结构.png)

其中Java堆（实例域，静态域和数组元素）和方法区的区域是多个线程共享的数据区域。也就是说，多个线程可能可以操作保存在堆或者方法区中的同一个数据。这也就是我们常说的“Java的线程间通过共享内存进行通信”。

JVM内存结构，由Java虚拟机规范定义。描述的是Java程序执行过程中，由JVM管理的不同数据区域。各个区域有其特定的功能。

局部变量（Local variables），方法定义参数（java 语言规范称之为 formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。

# Java 内存模型

Java内存模型是根据英文Java Memory Model（JMM）翻译过来的。其实JMM并不像JVM内存结构一样是真实存在的。他只是一个抽象的概念。JMM是和多线程相关的，他描述了一组规则或规范，这个规范定义了一个线程对共享变量的写入时对另一个线程是可见的。

Java的多线程之间是通过共享内存进行通信的，而由于采用共享内存进行通信，在通信过程中会存在一系列如可见性、原子性、顺序性等问题，而JMM就是围绕着多线程通信以及与其相关的一系列特性而建立的模型。JMM定义了一些语法集，这些语法集映射到Java语言中就是volatile、synchronized等关键字。

![](.\png\java内存模型.png)

## 概念

**Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。**

Java内存模型描述了在多线程代码中哪些行为是合法的，以及线程如何通过内存进行交互。它描述了“程序中的变量“ 和 ”从内存或者寄存器获取或存储它们的底层细节”之间的关系。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。

## 原因

### 多线程缓存一致性

由于CPU和主存之间存在高速缓存，所以在多线程场景下会存在**缓存一致性问题**。

![](.\png\computer_内存架构.png)

在CPU内部有一组CPU寄存器，也就是CPU的储存器。CPU操作寄存器的速度要比操作计算机主存快的多。在主存和CPU寄存器之间还存在一个CPU缓存，CPU操作CPU缓存的速度快于主存但慢于CPU寄存器。某些CPU可能有多个缓存层（一级缓存和二级缓存）。计算机的主存也称作RAM，所有的CPU都能够访问主存，而且主存比上面提到的缓存和寄存器大很多。

当一个CPU需要访问主存时，会先读取一部分主存数据到CPU缓存，进而在读取CPU缓存到寄存器。当CPU需要写数据到主存时，同样会先flush寄存器到CPU缓存，然后再在某些节点把缓存数据flush到主存。


一个CPU中的线程读取主存数据到CPU缓存，然后对共享对象做了更改，但CPU缓存中的更改后的对象还没有flush到主存，此时线程对共享对象的更改对其它CPU中的线程是不可见的。最终就是每个线程最终都会拷贝共享对象，而且拷贝的对象位于不同的CPU缓存中。

### 处理器优化和指令重排

为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是**处理器优化**。

除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做**指令重排**。

由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。**内存系统会重排序**

![](.\png\java_并发_重排序.png)

对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的**内存屏障**（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。

为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。

### 重排序原则

#### 数据依赖性

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。

编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。

##### 注意

这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。

#### as-if-serial语义

不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。

### 顺序一致性

和顺序一致性模型一样，未同步程序在 JMM 中的执行时，整体上也是无序的，其执行结果也无法预知。同时，未同步程序在这两个模型中的执行特性有下面几个差异：

1. 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。
2. 序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。
3. JMM 不保证对 64 位的 long 型和 double 型变量的读 / 写操作具有原子性，而顺序一致性模型保证对所有的内存读 / 写操作都具有原子性。

### 并发编程问题汇总

原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。

#### 原子性（处理器优化）

指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。

#### 可见性（缓存一致性）

指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

#### 有序性（指令重排）

程序执行的顺序按照代码的先后顺序执行。

## 支撑Java内存模型的基础原理

### 指令重排序

### happens-before

### 使用内存屏障

#### 内存屏障指令分类

|      屏障类型       |          指令示例          | 说明                                                         |
| :-----------------: | :------------------------: | :----------------------------------------------------------- |
|  LoadLoad Barriers  |   Load1; LoadLoad; Load2   | 确保 Load1 数据的装载，之前于 Load2 及所有后续装载指令的装载。 |
| StoreStore Barriers | Store1; StoreStore; Store2 | 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Store2 及所有后续存储指令的存储。 |
| LoadStore Barriers  |  Load1; LoadStore; Store2  | 确保 Load1 数据装载，之前于 Store2 及所有后续的存储指令刷新到内存。 |
| StoreLoad Barriers  |  Store1; StoreLoad; Load2  | 确保 Store1 数据对其他处理器变得可见（指刷新到内存），之前于 Load2 及所有后续装载指令的装载。StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 |

StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。

## 原型

Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的**工作内存**和**主存**之间进行数据同步进行。

而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。

## java内存模型的实现

在Java中提供了一系列和并发处理相关的关键字，比如`volatile`、`synchronized`、`final`、`concurren`包等。

### 原子性

在Java中，为了保证原子性，提供了两个高级的字节码指令`monitorenter`和`monitorexit`。这两个字节码，在Java中对应的关键字就是**`synchronized`**。

### 可见性

Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。

Java中的**`volatile`**关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用`volatile`来保证多线程操作时变量的可见性。

### 有序性

在Java中，可以使用`synchronized`和`volatile`来保证多线程之间操作的有序性。实现方式有所区别：

`volatile`关键字会禁止指令重排。`synchronized`关键字保证同一时刻只允许一条线程操作。

## 缓存一致性（可见性）

### 处理缓存一致性方式

1. 通过在总线加 lock 锁的方式
2. 通过缓存一致性协议

### 缓存一致性协议

缓存一致性协议（Cache Coherence Protocol），解决多个缓存副本之间的数据的一致性问题。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。**（可见性）**

#### MESI的核心的思想

当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。

#### 状态

在MESI协议中，每个缓存可能有4个状态，分别是：

**M(Modified)**：这行数据有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。

**E(Exclusive)**：这行数据有效，数据和内存中的数据一致，数据只存在于本Cache中。

**S(Shared)**：这行数据有效，数据和内存中的数据一致，数据存在于很多Cache中。

**I(Invalid)**：这行数据无效。

MESI是一种比较常用的缓存一致性协议，他可以用来解决缓存之间的数据一致性问题。值得注意的是，传统的MESI协议中有两个行为的执行成本比较大。

- 将某个Cache Line标记为Invalid状态
- 当某Cache Line当前状态为Invalid时写入新的数据。

所以CPU通过Store Buffer和Invalidate Queue组件来降低这类操作的延时。如图：

![](.\png\MESI协议-缓存一致性.png)

当一个CPU进行写入时，首先会给其它CPU发送Invalid消息，然后把当前写入的数据写入到Store Buffer中。然后异步在**某个时刻**真正的写入到Cache中。

当前CPU核如果要读Cache中的数据，需要先扫描Store Buffer之后再读取Cache。

但是此时其它CPU核是看不到当前核的Store Buffer中的数据的，要等到Store Buffer中的数据被刷到了Cache之后才会触发失效操作。

而当一个CPU核收到Invalid消息时，会把消息写入自身的Invalidate Queue中，随后**异步**将其设为Invalid状态。

和Store Buffer不同的是，当前CPU核心使用Cache时并不扫描Invalidate Queue部分，所以可能会**有极短时间的脏读问题**。

所以，为了解决缓存的一致性问题，比较典型的方案是MESI缓存一致性协议。

#### 说明

MESI协议，可以保证缓存的一致性，但是无法保证实时性。

## happen-before

JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。与程序员密切相关的 happens-before规则如下：

- 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。

- 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。

- volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。

- 线程上调用start()方法*happens* *before*这个线程启动后的任何操作。

- join()原则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回

- 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。

- 程序中断规则：对线程Interrupted() 方法的调用先行于被中断线程的代码检测到中断时间的发生。

- 对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。 （finalize() 方法是垃圾回收器回收时会调用的一个方法，方法原型为：）

  ```java
  protected void finalize(){
  	
  }
  ```

  

#### 注意

两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。

一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。

#### happens-before与JMM的关系如下图所示

![](.\png\happens-before与JMM关系.png)

## 示例

### volatile

见 并发编程-关键字-volatile

### 锁

见 并发编程-java锁 内存语义

### final

**对于final域，编译器和处理器要遵守两个重排序规则**：

1. 在构造函数内对一个 final 域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
2. 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。

下面通过一些示例代码来分别说明这两个规则：

```java
public class FinalExample{
    int i;		//普通变量
    final int j;
    static FinalExample obj;	//final变量
    
    public FinalExample(){		//构造函数
        i = 1;				//写普通域
        j = 2;				//写final域
    }
    
    public static void writer(){	//写线程A执行
        obj = new FinalExample();
    }
    
    public static void reader(){	//读线程B执行
        FinalExample object = obj;	//读对象引用
        int a = object.i;		//读普通域
        int b = object.j;		//读final域
    }
}
```

这里假设一个线程 A 执行 writer () 方法，随后另一个线程 B 执行 reader () 方法。下面我们通过这两个线程的交互来说明这两个规则。

#### 写final域的重排序规则

写final 域的重排序规则禁止把 final 域的写重排序到构造函数之外。这个规则的实现包含下面 2 个方面：

- JMM 禁止编译器把 final 域的写重排序到构造函数之外。
- 编译器会在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 屏障。这个屏障禁止处理器把 final 域的写重排序到构造函数之外。

writer () 方法只包含一行代码：finalExample = new FinalExample ()。这行代码包含两个步骤：

1. 构造一个 FinalExample 类型的对象；
2. 把这个对象的引用赋值给引用变量 obj。

假设线程 B **读**对象引用与读对象的成员域之间没有重排序（马上会说明为什么需要这个假设），下图是一种可能的执行时序：

![](.\png\java-final-写的重排规则.png)

在上图中，写普通域的操作被编译器重排序到了构造函数之外，读线程 B **错误的读取**了**普通变量 i** 初始化之前的值。而写 final 域的操作，被写 final 域的重排序规则“限定”在了构造函数之内，读线程 B **正确的读取**了 **final 变量**初始化之后的值。

写 final 域的重排序规则可以确保：**在对象引用为任意线程可见之前，对象的 final 域已经被正确初始化过了，而普通域不具有这个保障。**以上图为例，在读线程 B“看到”对象引用 obj 时，很可能 obj 对象还没有构造完成（对普通域 i 的写操作被重排序到构造函数外，此时初始值 1 还没有写入普通域 i）。

#### 读final域的重排序规则

读final 域的重排序规则如下：

在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作(注意，这个规则仅仅针对处理器)。编译器会在读final域操作的前面插入一个LoadLoad屏障。

初次读对象引用与初次读该对象包含的 final 域，这两个操作之间存在**间接依赖关系**。由于编译器遵守间接依赖关系，因此编译器不会重排序这两个操作。大多数处理器也会遵守间接依赖，大多数处理器也不会重排序这两个操作。但有少数处理器允许对存在间接依赖关系的操作做重排序（比如 alpha 处理器），这个规则就是专门用来针对这种处理器。

reader()方法包含三个操作：

1. 初次读引用变量obj
2. 初次读引用变量obj指向对象的普通域 j
3. 初次读引用变量obj指向对象的final 域 i

在读一个对象的 final 域之前，一定会先读包含这个 final 域的对象的引用。

#### final域是引用类型

```java
public class FinalReferenceExample{
    final int[] intArray;		//final是引用类型
    static FinalReferenceExample obj;
    
    public FinalReferenceExample(){	//构造函数
        intArray = new int[1];		//1
        intArray[0] = 1;			//2
    }
    
    public static void writerOne(){			//写线程 A 执行
        obj = new FinalReferenceExample();	//3
    }
    
    public static void writerTwo(){	//写线程 B 执行
        obj.intArray[0] = 2;		//4
    }
    
    public static void reader(){		//读线程 C 执行
        if(obj != null){		//5
            int temp1 = obj.intArray[0];	//6
        }
    }
}
```

##### 写final域的重排序规则

写final域的重排序规则对编译器和处理器增加了如下约束：

1. 在构造函数内对一个final引用的对象的**成员域**的写入，与随后在构造函数外把这个被**构造对象的引用**赋值给一个引用变量，这两个操作之间不能重排序。

假设首先线程 A 执行 writerOne() 方法，执行完后线程 B 执行 writerTwo() 方法，执行完后线程 C 执行 reader () 方法。下面是一种可能的线程执行时序：

![](.\png\java-final-引用类型-多线程并发-执行程序.png)

在上图中，1 是对 final 域的写入，2 是对这个 final 域引用的对象的成员域的写入，3 是把被构造的对象的引用赋值给某个引用变量。这里除了前面提到的 1 不能和 3 重排序外，2 和 3 也不能重排序。

JMM 可以确保读线程 C 至少能看到写线程 A 在构造函数中对 final 引用对象的成员域的写入。即 C 至少能看到数组下标 0 的值为 1。而写线程 B 对数组元素的写入，读线程 C 可能看的到，也可能看不到。JMM 不保证线程 B 的写入对读线程 C 可见，因为写线程 B 和读线程 C 之间存在数据竞争，此时的执行结果不可预知。

如果想要确保读线程 C 看到写线程 B 对数组元素的写入，写线程 B 和读线程 C 之间需要使用同步原语（lock 或 volatile）来确保内存可见性。

#### final引用不能从构造函数内"逸出"

写 final 域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的 final 域已经在构造函数中被正确初始化过了。其实要得到这个效果，还需要一个保证：在构造函数内部，**不能让这个被构造对象的引用为其他线程可见**，也就是对象引用不能在构造函数中“逸出”。

```java
public class FinalReferenceEscapeExample{
    final int i;
    static FinalReferenceEscapeExample obj;
    
    public FinalReferenceEscapeExample(){
        i = 1;		//1 写final域
        obj = this;	//2 this 引用在此“逸出”
    }
    
    public static void writer(){
        new FinalReferenceEscapeExample();
    }
    
    public static void reader(){
        if(obj != null){		//3
            int temp = obj.i;	//4
        }
    }
}
```

假设一个线程 A 执行 writer() 方法，另一个线程 B 执行 reader() 方法。**这里的操作 2 使得对象还未完成构造前就为线程 B 可见**。即使这里的操作 2 是构造函数的最后一步，且即使在程序中操作 2 排在操作 1 后面，执行 read() 方法的线程仍然可能无法看到 final 域被初始化后的值，因为这里的操作 1 和操作 2 之间可能被重排序。实际的执行时序可能如下图所示：

![](.\png\java-final引用从构造函数逸出.png)

在构造函数返回前，被构造对象的引用不能为其他线程可见，因为此时的 final 域可能还没有被初始化。在构造函数返回后，任意线程都将保证能看到 final 域正确初始化之后的值。

#### final语义在处理器中的实现

写 final 域的重排序规则会要求译编器在 final 域的写之后，构造函数 return 之前，插入一个 StoreStore 障屏。读 final 域的重排序规则要求编译器在读 final 域的操作前面插入一个 LoadLoad 屏障。

由于 x86 处理器不会对写 - 写操作做重排序，所以在 x86 处理器中，写 final 域需要的 StoreStore 障屏会被省略掉。同样，由于 x86 处理器不会对存在间接依赖关系的操作做重排序，所以在 x86 处理器中，读 final 域需要的 LoadLoad 屏障也会被省略掉。也就是说在 x86 处理器中，final 域的读 / 写不会插入任何内存屏障！

#### JSR-133为什么要增强final的语义

在旧的 Java 内存模型中 ，最严重的一个缺陷就是线程可能看到 final 域的值会改变。比如，一个线程当前看到一个整形 final 域的值为 0（还未初始化之前的默认值），过一段时间之后这个线程再去读这个 final 域的值时，却发现值变为了 1（被某个线程初始化之后的值）。最常见的例子就是在旧的 Java 内存模型中，String 的值可能会改变。

为了修补这个漏洞，JSR-133 专家组增强了 final 的语义。通过为 final 域增加写和读重排序规则，可以为 java 程序员提供初始化安全保证：**只要对象是正确构造**的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指 lock 和 volatile 的使用），就可以保证任意线程都能看到这个 final 域在构造函数中被初始化之后的值。

## 总结

### JMM重排序策略

JMM把happens-before 要求禁止的重排序分为了下面两类：

- 会改变程序执行结果的重排序
- 不会改变程序执行结果的重排序

JMM对这两种不同性质的重排序，采取了不同的策略：

- 对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序
- 对于不会改变程序执行结果的重排序，JMM对编译器和处理器不作要求(JMM允许这种重排序)

下面是JMM的设计示意图：

![](.\png\JMM设计示意图.png)

### JMM可见性保证

Java 程序的内存可见性保证按程序类型可以分为下列三类：

1. 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime 和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。
2. 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是 JMM 关注的重点，JMM 通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。
3. 未同步 / 未正确同步的多线程程序。JMM 为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。

下图展示了这三类程序在 JMM 中与在顺序一致性内存模型中的执行结果的异同：

![](.\png\JMM与顺序一致性内存模型中的执行结果异同.png)

只要多线程程序是正确同步的，JMM 保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。

# JAVA 对象模型

关于Java对象自身的存储模型称之为Java对象模型。



每一个Java类，在被JVM加载的时候，JVM会给这个类创建一个`instanceKlass`，保存在方法区，用来在JVM层表示该Java类。当我们在Java代码中，使用new创建一个对象的时候，JVM会创建一个`instanceOopDesc`对象，这个对象中包含了对象头以及实例数据。

![](.\png\java对象模型.jpeg)

## 总结

JVM内存结构，和Java虚拟机的**运行时区域**有关。 

Java内存模型，和Java的**并发编程**有关。

 Java对象模型，和Java对象在虚拟机中的**表现形式**有关。

# 并发编程

## 线程之间的通信和同步

### 通信

- 共享内存	通过写-读内存中的公共状态来隐式进行通信。（共享对象）
- 消息传递    线程之间通过明确的发送消息来显式进行通信。（典型wait() 和 notify()）

### 同步

用于控制不同线程之间操作发生相对顺序的机制。

- 共享内存	同步是显式进行的
- 消息传递    隐式进行

## Java锁

### 锁的内存语义

- 锁可以让临界区互斥执行，还可以让释放锁的线程向同一个锁的线程发送消息
- 锁的释放要遵循Happens-before原则（`锁规则：解锁必然发生在随后的加锁之前`）
- 锁在Java中的具体表现是 `Synchronized` 和 `Lock`

#### 锁的释放的内存语义

线程A释放锁后，会将共享变更操作刷新到主内存中。

![](.\png\java_lock_release.jpg)

#### 锁的获取的内存语义

线程B获取锁时，JMM会将该线程的本地内存置为无效，被监视器保护的临界区必须从主内存中读取共享变量

![](.\png\java_lock_acquire.jpg)

#### 锁的释放与获取过程

- 锁获取与 volatile 读有相同的内存语义，可见**关键字 volatile**
- 线程A释放一个锁，实质是线程A告知下一个获取到该锁的某个线程其已变更该共享变量
- 线程B获取一个锁，实质是线程B得到了线程A告知其(在释放锁之前)变更共享变量的消息
- 线程A释放锁，随后线程B竞争到该锁，实质是线程A通过主内存向线程B发消息告知其变更了共享变量

#### 锁释放-获取示例代码

```java
class MonitorExample{
    int a = 0;
    
    public synchronized void writer(){//1
        a++;	//2
    }			//3
    
    public synchronized void reader(){//4
        int i = a;		//5
        ...		
    }					//6
}
```

假设线程 A 执行 writer() 方法，随后线程 B 执行 reader() 方法。根据 happens before 规则，这个过程包含的 happens before 关系可以分为两类：

1. 根据程序次序规则，1 happens before 2, 2 happens before 3; 4 happens before 5, 5 happens before 6。
2. 根据监视器锁规则，3 happens before 4。
3. 根据 happens before 的传递性，2 happens before 5。

上述 happens before 关系的图形化表现形式如下：

![](.\png\java-锁-happens_before图形化表示.png)

在上图中，每一个箭头链接的两个节点，代表了一个 happens before 关系。

黑色箭头表示程序顺序规则；

橙色箭头表示监视器锁规则；

蓝色箭头表示组合这些规则后提供的 happens before 保证。

### 锁内存语义的实现

借助 ReentrantLock 的源代码，来分析锁内存语义的具体实现机制。

#### 示例代码

```java
class ReentrantLockExample{
    int a  =0;
    
    ReentrantLock lock = new ReentrantLock();
    
    public void writer(){
        lock.lock();	//获取锁
        try{
            a++;
        }finally{
            lock.unlock();	//释放锁
        }
    }
    
    public void reader(){
        lock.lock();	//获取锁
        try{
            int i = a;
            ...
        }finally{
            lock.unlock();	//释放锁
        }
    }
}
```

在 ReentrantLock 中，调用 lock() 方法获取锁；调用 unlock() 方法释放锁。

ReentrantLock 的实现依赖于 java 同步器框架 AbstractQueuedSynchronizer（本文简称之为 AQS）。AQS 使用一个整型的 volatile 变量（命名为 state）来维护同步状态，马上我们会看到，这个 volatile 变量是 ReentrantLock 内存语义实现的关键。 下面是 ReentrantLock 的类图（仅画出与本文相关的部分）：

![](.\png\java-锁-ReentrantLock类图.png)

ReentrantLock 分为公平锁和非公平锁，我们首先分析公平锁。

使用公平锁时，加锁方法 lock() 的方法调用轨迹如下：

1. ReentrantLock：lock()
2. FairSync：lock()
3. AbstractQueuedSynchronizer：acquire(int arg)
4. ReentrantLock：tryAcquire(int acquires)

在第 4 步真正开始加锁，下面是该方法的源代码：

```java
protected final boolean tryAcquire(int acquires){
    final Thread current = Thread.currentThread();
    int c = getState();	//获取锁的开始，首先读volatile变量 state
    if(c == 0){
        if (isFirst(current) &&
            compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }else if(current == getExclusiveOwnerThread()){
        int nextc = c + acquires;
        if (nextc < 0)  
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

从上面源代码中我们可以看出，加锁方法首先读 volatile 变量 state。

##### compareAndSetState

```java
protected final boolean compareAndSetState(int expect, int update) {
    return unsafe.compareAndSwapInt(this, stateOffset, expect, update);
}
```

该方法以原子操作的方式更新 state 变量，本文把 java 的 compareAndSet() 方法调用简称为 **CAS**。

编译器不会对 volatile 读与 volatile 读后面的任意内存操作重排序；编译器不会对 volatile 写与 volatile 写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现 volatile 读和 volatile 写的内存语义，编译器不能对 CAS 与 CAS 前面和后面的任意内存操作重排序。



在使用公平锁时，解锁方法unlock() 方法调用轨迹如下：

1. ReentrantLock : unlock()
2. AbstractQueuedSynchronizer : release(int arg)
3. Sync : tryRelease(int releases)

在第 3 步真正开始释放锁，下面是该方法的源代码：

```java
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);           // 释放锁的最后，写 volatile 变量 state
    return free;
}
```

从上面的源代码我们可以看出，在释放锁的最后写 volatile 变量 state。

公平锁在释放锁的最后写 volatile 变量 state；在获取锁时首先读这个 volatile 变量。根据 volatile 的 happens-before 规则，释放锁的线程在写 volatile 变量之前可见的共享变量，在获取锁的线程读取同一个 volatile 变量后将立即变的对获取锁的线程可见。

##### 公平锁与非公平锁的内存语义总结

- 公平锁和非公平锁释放时，最后都要写一个volatile变量 state。
- 公平锁获取时，首先会去读这个volatile变量
- 非公平锁获取时，首先会用CAS更新这个volatile变量，这个操作同时具有volatile读和volatile写的内存语义

### 锁对象、类锁、私有锁

#### 对象锁

使用 synchronized 修饰**非静态**的方法以及 synchronized(this) 同步代码块使用的锁是对象锁。

#### 类锁 

使用 synchronized 修饰**静态**的方法以及 synchronized(**class**) 同步代码块使用的锁是类锁

#### 私有锁

在类内部声明一个私有属性如private Object lock，在需要加锁的同步块使用 synchronized(lock）

特殊的instance变量

```java
private byte[] lock = new byte[0];	//特殊的instance变量
public void method(){
    synchronized(lock){
        //TODO 同步代码块
    }
}
```

##### 说明

零长度的byte数组对象创建起来将比任何对象都经济――查看编译后的字节码：生成零长度的byte[]对象只需3条操作码，而Object lock = new Object()则需要7行操作码。

#### 特性

- 对象锁具有可重入性
- 当一个线程获得了某个对象的对象锁，则该线程仍然可以调用其他任何需要该对象锁的 synchronized 方法或 synchronized(this) 同步代码块
- 当一个线程访问某个对象的一个 synchronized(this) 同步代码块时，其他线程对该对象中所有其它 synchronized(this) 同步代码块的访问将被阻塞，因为访问的是同一个对象锁。
- 每个类只有一个类锁，但是类可以实例化成对象，因此每一个对象对应一个对象锁
- 类锁和对象锁不会产生竞争。
- 私有锁和对象锁也不会产生竞争。
- 使用私有锁可以减小锁的细粒度，减少由锁产生的开销。

由私有锁实现的等待/通知机制：

```java
Object lock = new Object();
//由等待方线程实现
synchronized(lock){
    while(条件不满足){
        lock.wait();
    }
}

//由通知方线程实现
synchronized(lock){
    //条件发生改变
    lock.notify();
}
```

### 死锁

#### 概念

死锁是两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。死锁通常发生在多个线程同时但以不同的顺序请求**同一组锁**的时候。

#### 避免死锁

##### 加锁顺序

如果一个线程（比如线程 3）需要一些锁，那么它必须按照确定的顺序获取锁。它只有获得了从顺序上排在前面的锁之后，才能获取后面的锁。

```java
Thread 1:
	lock A 
	lock B

Thread 2:
	wait for A
	lock C (when A locked)

Thread 3:
	wait for A
	wait for B
	wait for C
```

按照顺序加锁是一种有效的死锁预防机制。但是，这种方式需要你事先知道所有可能会用到的锁，但总有些时候是无法预知的。

##### 加锁时限

在尝试**获取锁的时候加一个超时时间**，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。这段随机的等待时间让其它线程有机会尝试获取相同的这些锁，并且让该应用在没有获得锁的时候可以继续运行。

##### 死锁检测

死锁检测是一个更好的死锁预防机制，它主要是针对那些不可能实现按序加锁并且锁超时也不可行的场景。

###### 原理

每当一个线程获得了锁，会在线程和锁相关的数据结构中（map、graph 等等）将其记下。除此之外，每当有线程请求锁，也需要记录在这个数据结构中。

当一个线程请求锁失败时，这个线程可以遍历锁的关系图看看是否有死锁发生。

### 锁分类（概念）

![](.\png\java_lock.png)

#### 乐观锁 VS 悲观锁

##### 悲观锁

对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。

##### 乐观锁

乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。

乐观锁在Java中是通过使用无锁编程来实现，最常采用的是**CAS算法**，Java原子类中的递增操作就通过CAS自旋实现的。

jdk5增加了并发包java.util.concurrent.*,其下面的类使用CAS算法实现了区别于synchronouse同步锁的一种乐观锁。

##### CAS算法（比较与交换）

CAS是一种无锁算法，CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

就是指当两者进行比较时，如果相等，则证明共享数据没有被修改，替换成新值，然后继续往下运行；如果不相等，说明共享数据已经被修改，放弃已经所做的操作，然后重新执行刚才的操作。容易看出 CAS 操作是基于共享数据不会被修改的假设，采用了类似于数据库的commit-retry 的模式。当同步冲突出现的机会很少时，这种假设能带来较大的性能提升。

![](.\png\java_lock_悲观和乐观.png)

###### 特性

- 通过调用JNI的代码实现
- 非阻塞算法
- 非独占锁

###### 乐观锁CAS缺点

- ABA问题。

  CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。

  - JDK从1.5开始提供了**AtomicStampedReference**类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。

- 循环时间长开销大。

  CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。

- 只能保证一个共享变量的原子操作。

  对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

  - Java从1.5开始JDK提供了**AtomicReference**类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。

###### 使用场景

- 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。
- 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。

###### 示例

```java
// ------------------------- 悲观锁的调用方式 -------------------------
// synchronized
public synchronized void testMethod() {
	// 操作同步资源
}
// ReentrantLock
private ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁
public void modifyPublicResources() {
	lock.lock();
	// 操作同步资源
	lock.unlock();
}

// ------------------------- 乐观锁的调用方式 -------------------------
private AtomicInteger atomicInteger = new AtomicInteger();  // 需要保证多个线程使用的是同一个AtomicInteger
atomicInteger.incrementAndGet(); //执行自增1
```

java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义：

```java
public class AtomicInteger extends Number implements java.io.Serializable{
	private static final long serialVersionUID = 6214790243416807050L;
	
	//setup to use Unsafe.compareAndSwapInt for updates
	private static final Unsafe unsafe = Unsafe.getUnsafe();
	private static final long valueOffset;
    
    static{
        try{
            valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField("value"));
        }catch(Exception e){
            throw new Error(ex);
        }
    }
    private volatile int value;
}
```

unsafe：获取并操作内存的数据

valueOffset：存储value在AtomicInteger中的偏移量

value：存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。

```java
// ------------------------- JDK 8 -------------------------
// AtomicInteger 自增方法
public final int incrementAndGet() {
  return unsafe.getAndAddInt(this, valueOffset, 1) + 1;
}

// Unsafe.class
public final int getAndAddInt(Object var1, long var2, int var4) {
  int var5;
  do {
      var5 = this.getIntVolatile(var1, var2);
  } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
  return var5;
}

// ------------------------- OpenJDK 8 -------------------------
// Unsafe.java
public final int getAndAddInt(Object o, long offset, int delta) {
   int v;
   do {
       v = getIntVolatile(o, offset);
   } while (!compareAndSwapInt(o, offset, v, v + delta));
   return v;
}
```

getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。

###### 总结

乐观锁的使用：通过CAS算法保证数据的同步性或者 CAS算法+版本号来保证数据的同步性。

#### 自旋锁 VS 适应性自旋锁

##### 自旋锁

阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。

在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。

而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。

![](.\png\java_自旋锁.png)

自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。

**自旋锁的实现原理同样也是CAS**，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。

```java
public final int getAndAddInt(Object var1,long var2,int var4){
    int var5;
    do{
        var5 =  this.getIntVolatile(var1,var2);
    }while(!this.compareAndSwapInt(var1,var2,var5,var5+var4));
    return var5;
}
```

自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。

##### 适应性自旋锁

自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

在自旋锁中另有三种常见的锁形式：TicketLock、CLHlock 和MCSlock。

#### 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁

| 锁状态   | 存储内容                                                | 存储内容 |
| -------- | ------------------------------------------------------- | -------- |
| 无锁     | 对象的hashCode、对象分代年龄、是否是偏向锁（0）         | 01       |
| 偏向锁   | 偏向线程ID、偏向时间戳、对象分代年龄、是否是偏向锁（1） | 01       |
| 轻量级锁 | 指向栈中锁记录的指针                                    | 00       |
| 重量级锁 | 指向互斥量（重量级锁）的指针                            | 10       |

##### 无锁

无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。

无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。

##### 偏向锁

偏向锁是指**一段同步代码一直被一个线程所访问**，那么该线程会自动获取锁，降低获取锁的代价。

在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。

##### 轻量级锁

是指当锁是偏向锁的时候，被另外的线程所访问，**偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能**。

在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。

拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。

如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。

如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。

若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。

##### 重量锁

升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。



综上，偏向锁通过**对比Mark Word**解决加锁问题，避免执行CAS操作。而轻量级锁是通过用**CAS操作和自旋**来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。

#### 公平锁 VS 非公平锁

##### 公平锁

公平锁是指多个线程按照申请锁的顺序来获取锁，**线程直接进入队列中排队，队列中的第一个线程才能获得锁**。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

##### 非公平锁

非公平锁是**多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待**。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。

通过ReentrantLock的源码来讲解公平锁和非公平锁

```java
public class ReentrantLock implements Lock,java.io.Serializable{
    private static final long serialVersion = 7373984872572414699L;
    private final Sync sync;
    
    abstarct static class Sync extends AbstractQueuedSynchronizer{...}
    
    static final class NonfairSync extends Sync{...}
    
    static final class FairSync extends Sync{...}
    
    public ReentrantLock(){ sync = new  NonfairSync();}
    
    public ReentrantLock(boolean fair){sync = fair ? new FairSync():new NonfairSync();}
}
```

根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。

##### 公平锁代码

```java
protected final boolean tryAcquire(int acquires){
    final Thread current = Thread.currentThread();
    int c = getState();
    if(c == 0){
        if(!hasQueuePrecessors() && compareAndSetState(0,acquires)){
            setExclusiveOwnerThread(current);
            return true;
        }
    }else if(current == getExclusiveOwnerThread()){
        int nextc = c+ acquires;
        if(next < 0){
            throw new Error("Maxium lock count exceeded");
        }
        setState(nextc);
        return true;
    }
    return false;
}
```

##### 非公平锁代码

```java
final boolean nonfairTryAcquire(int acquires){
    final Thread current = Thread.currentThread();
    int c = getState();
    if(c == 0){
        if(compareAndSetState(0,acquires)){
            setExclusiveOwnerThread(current);
            return true;
        }
    }else if(current == getExclusiveOwnerThread()){
        int nextc = c +acquires;
        if(nextc<0){
            throw new Error("Maxium lock count exceeded");
        }
        setState(nextc);
        return true;
    }
    return false;
}
```

##### 同步与非同步的差别

```java
public final boolean hasQueuedPredecessors(){
    //...
    Node t = tail;
    Node h = head;
    Node s;
    return h != t && ((s = h.next) == null || s.thread != Thread.currentThread());
}
```

该方法主要判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。

#### 可重入锁 VS 非可重入锁

##### 可重入锁

可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中**ReentrantLock和synchronized都是可重入锁**，可重入锁的一个优点是可一定程度避免死锁。

```java
public class Widget{
    public synchronized void doSomething(){
        System.out.println("方法1执行....");
        doOthers();
    }
    public synchronized void doOthers(){
        System.out.println("方法2执行...");
    }
}
```

因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。

##### 非可重入锁

NonReentrantLock为非可重入锁。

通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。

首先ReentrantLock和NonReentrantLock都继承父类**AQS**，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。

##### 非可重入锁死锁的原因

###### 获取锁

当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。

###### 释放锁

释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。

##### 可重入锁代码

```java
final boolean nonfairTryAcquire(int acquires){
    final Thread current = Thread.currentThread();
    int c = getState();
    if(c == 0){
        if(compareAndSetState(0,acquires)){
            setExclusiveOwnerThread(current);
            return true;
        }
    }else if(current == getExclusiveOwnerThread()){
        int nextc = c+acquires;
        if(nextc <0){
            throw new Error("Maxium lock count exceeded");
        }
        setState(nextc);
        return true;
    }
    return false;
}
//获取锁时先判断，如果当前线程就是已经占有锁的线程，则status值+1，并返回true。

protected final boolean tryRelease(){
    int c =  getState() - release;
    if(Thread.currentThread() != getExclusiveOwnerThread()){
        throw new IllegalMonitorStateException();
    }
    boolean free = false;
    if(c == 0){
        free = false;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
//释放锁时也是先判断当前线程是否已占有锁的线程，然后再判断status，如果status等于0，才真正的释放锁
```

##### 非可重入锁代码

```java
protected boolean tryAcquire(int acquires){
    if(this.compareAndSetState(0,1)){
        this.owner = Thread.currentThread();
        return true;
    }else {
        return false;
    }
}
//非重入锁是直接尝试获取锁

protected boolean tryRelease(int releases){
    if(Thread.currentThread() != this.owner){
        throw new IllegalMonitorStateException();
    }else{
        this.owner = null;
        this.setState(0);
        return true;
    }
}
//释放锁时直接将status 置为0
```

#### 分段锁

分段锁其实是一种锁的设计，并不是具体的一种锁，对于`ConcurrentHashMap`而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。

`ConcurrentHashMap`中的分段锁称为Segment，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。

当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。

但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。

分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。

#### 独享锁 VS 共享锁

##### 独享锁

独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC（java.utils.current）中Lock的实现类就是互斥锁。

##### 共享锁

共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。**ReentrantReadWriteLock**

##### 实现

独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。

###### ReentrantReadWriteLock的部分源码：

```java
public class ReentrantReadWriteLock implements ReadWriteLock,java.io.Serializable{
    private static final long serialVersionUID = -5992448646407608164L;
    
    private final ReentrantReadWriteLock.ReadLock readerLock;
    
    private final ReentrantWriteLock.WriteLock writeLock;
    
    final Sync sync;
    
    public ReentrantReadWriteLock(this(false));
    
    public ReentrantReadWriteLock(boolean fair){
        sync= fair ? new FairSync() : new NonFairSync();
        readLock = new ReadLock(this);
        writeLock = new WriteLock(this);
    }
    public ReentrantReadWriteLock.WriteLock writeLock(){
        return writeLock;
    }
    public ReentrantReadWriteLock.ReadLock readLock(){
        return readLock;
    }
}
```

###### 读锁

读锁为一个可重入的共享锁，能够被多个线程同时持有，在没有其他写线程访问时，读锁总是获取成功。

###### ReadLock

```java
public static class ReadLock implements Lock,java.io.Serializable{
    private static final long serialVersionUID = -5992648646407699164L;
    private final Sync sync;
    
    protected ReadLock(ReentrantReadWriteLock lock){
        sync = lock.sync;
    }
}
```

###### 读锁的获取

```java
public void lock(){
	sync.acquireShared(1);
}
```

```java
public final void acquireShared(int arg){
	if(tryAcquireShared(arg)<0){
		doAcquireShared(arg);
	}
}
```

###### 读锁的释放

```java
public void unlock(){
	sync.releaseShared(1);
}
```

```java
public final boolean releaseShared(int arg) {
	if (tryReleaseShared(arg)) {
		doReleaseShared();
		return true;
	}
	return false;
}
```

###### 写锁

写锁就是一个支持可重入的排他锁。

###### WriteLock

```java
public static class WriteLock implements Lock,java.io.Serializable{
    private static final long serialVersionUID = -4992448646487698164L;
    private final Sync sync;
    
    protected WriteLock(ReentrantReadWriteLock lock){
        sync = lock.sync;
    }
}
```

###### 写锁的获取

写锁的获取最终会调用tryAcquire(int arg)，该方法在内部类Sync中实现。（见写锁的加锁源码）

###### 写锁的释放

获取了写锁用完了则需要释放，WriteLock提供了unlock()方法释放写锁：

```java
public void unlock(){
    sync.release(1);
}
public final boolean release(int arg){
    if(tryRelease(arg)){
        Node h = head;
        if(h!=null && h.waitStatus !== 0){
            unparkSuccessor(h);
        }
        return true;
    }
    return false;
}
```

可以看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。

在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。

在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图：

![](.\png\java_sync_state_共享锁.png)

###### 读写锁的主要特性

1. 公平性：支持公平性和非公平性
2. 重入性：支持重入。读写锁最多支持 65535 个递归写入锁和 65535 个递归读取锁。
3. 锁降级：遵循**获取写锁、获取读锁再释放写锁**的次序，写锁能够降级成为读锁。（占有写锁的线程可以获取读锁）

###### 写锁的加锁源码

```java
protected final boolean tryAcquire(int acquires){
    Thread current = Thread.currentThread();
    int c = getState();	//获取当前锁的个数
    int w = exclusiveCount(c);	//获取写锁的个数
    if(c != 0){//如果已经有线程持有了锁 (c!=0)
// (Note: if c != 0 and w == 0 then shared count != 0)
		if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败
			return false;
		if (w + exclusiveCount(acquires) > MAX_COUNT)    // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。
			throw new Error("Maximum lock count exceeded");
		// Reentrant acquire
		setState(c + acquires);
		return true;
	}
	if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) 
	// 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。
		return false;
	setExclusiveOwnerThread(current); 
    // 如果c=0，w=0或者c>0，w>0（重入），则设置当前线程或锁的拥有者
	return true;
}
```

- 首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。
- 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。
- 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error
- 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败
- 如果c=0,w=0或者c>0,w>0（重入），则设置当前线程或锁的拥有者，返回成功

只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。

###### 读锁的代码

```java
protected final int tryAcquireShared(int unused) {
    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &&
        getExclusiveOwnerThread() != current)
        return -1;                                   
    // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态
    int r = sharedCount(c);
    if (!readerShouldBlock() &&
        r < MAX_COUNT &&
        compareAndSetState(c, c + SHARED_UNIT)) {
        if (r == 0) {
            firstReader = current;
            firstReaderHoldCount = 1;
        } else if (firstReader == current) {
            firstReaderHoldCount++;
        } else {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != getThreadId(current))
                cachedHoldCounter = rh = readHolds.get();
            else if (rh.count == 0)
                readHolds.set(rh);
            rh.count++;
        }
        return 1;
    }
    return fullTryAcquireShared(current);
}
```

在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1<<16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。

###### HoldCounter

与线程有关的状态计数器。

### synchronized

#### 基础

Java中的每一个对象都可以作为锁。

#### 使用方式

- 修饰代码块
- 修饰方法
- 修饰一个静态方法
- 修饰一个类

#### 状态

synchronized 同步锁一共包含四种状态：无锁、偏向锁、轻量级锁、重量级锁，它会随着竞争情况逐渐升级。synchronized 同步锁**可以升级但是不可以降级**，目的是为了提高获取锁和释放锁的效率。

#### 特性

java中synchronized关键字是同步锁，同步锁是依赖于对象而存在的，而且每一个对象有且仅有一个同步锁。当我们调用某对象的synchronized方法时，就获取了该对象的同步锁。

#### 概念锁

无锁->偏向锁->轻量锁->重量锁

悲观锁

可重入锁

### ReentrantLock

ReentrantLock 是一个独占/排他锁。相对于 synchronized，它更加灵活。但是需要自己写出加锁和解锁的过程。它的灵活性在于它拥有很多特性。

#### 特性

- 公平性：支持公平锁和非公平锁。默认使用了非公平锁。
- 可重入：
- 可中断：相对于synchronized，它湿可中断的锁，能够对中断作出响应。
- 超时机制：超时后不能获得锁，因此不会造成死锁。

#### 注

1. ReentrantLock 需要显示地进行释放锁。特别是在程序异常时，synchronized 会自动释放锁，而 ReentrantLock 并不会自动释放锁，所以必须在 finally 中进行释放锁。
2. ReentrantLock 是很多类的基础，例如 ConcurrentHashMap 内部使用的 Segment 就是继承 ReentrantLock，CopyOnWriteArrayList 也使用了 ReentrantLock。

### 概念锁

公平锁

非公平锁

可重入锁

### NonReentrantLock

#### 概念锁

非可重入锁

### ReentrantReadWriteLock

它拥有读锁(ReadLock)和写锁(WriteLock)，读锁是一个共享锁，写锁是一个排他锁。

#### 特性

- 公平性：支持公平锁和非公平锁。默认使用了非公平锁。
- 可重入：读线程在获取读锁之后能够再次获取读锁。写线程在获取写锁之后能够再次获取写锁，同时也可以获取读锁（锁降级）。
- 锁降级：先获取写锁，再获取读锁，然后再释放写锁的过程。锁降级是为了保证数据的可见性。

#### 概念锁

共享锁

### Object

wait()、notify()、notifyAll()。

#### 特别说明

wait() 调用时会释放锁。

### Condition

Condition 用于替代传统的 Object 的 wait()、notify() 实现线程间的协作。

#### 说明

在Condition 对象中，与 wait、notify、notifyAll 方法对应的分别是 await、signal 和 signalAll。

#### 特性

- 一个 Lock 对象可以创建多个 Condition 实例，所以可以支持多个等待队列。
- Condition 在使用 await、signal 或 signalAll 方法时，必须先获得 Lock 的 lock()
- 支持响应中断
- 支持的定时唤醒功能

#### 注

Condition 必须要配合 Lock 一起使用，一个 Condition 的实例必须与一个 Lock 绑定。

### Semaphore

Semaphore、CountDownLatch、CyclicBarrier 都是并发工具类。

Semaphore 可以指定多个线程同时访问某个资源，而 synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源。由于 Semaphore 适用于限制访问某些资源的线程数目，因此可以使用它来做**限流**。

#### 注

Semaphore 并不会实现数据的同步，数据的同步还是需要使用 synchronized、Lock 等实现。

#### 特性

- 基于AQS 的共享模式
- 公平性：支持公平模式和非公平模式。默认使用了非公平模式。

### CountDownLatch

CountDownLatch 可以看成是一个倒计数器，它允许一个或多个线程等待其他线程完成操作。因此，CountDownLatch 是共享锁。

CountDownLatch 的 countDown() 方法将计数器减1，await() 方法会阻塞当前线程直到计数器变为0。

### 总结

![](.\png\java锁_小结.png)

## 线程

### 线程与进程

#### 进程：

每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。（**进程是资源分配的最小单位**）

#### 线程：

同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。（**线程是cpu调度的最小单位**）



线程和进程一样分为五个阶段：创建、就绪、运行、阻塞、终止。

多进程是指操作系统能同时运行多个任务（程序）。

线程是指在同一程序中有多个顺序流在执行。

### 新建线程

#### Thread

继承Thread类，重写 run 方法

```java
Thread thread = new Thread(){
    @Override
    public void run(){
        System.out.println("继承Thread");
        super.run();
    }
}
thread.start();
```

##### 注

- start() 方法的调用后并不是立即执行多线程代码，而是使得该线程变为可运行态，什么时候运行是由操作系统决定的。
- start() 方法重复调用的话，会出现java.lang.IllegalThreadStateException异常。



#### Runnable

实现runnable接口

```java
Thread thread = new Thread(new Runnable(){
   @Override
    public void run(){
        System.out.println("实现runnable接口")
    }
});
thread.start();
```

##### 注

- Thread类实际上也是实现了Runnable接口的类。
- 在启动多线程的时候，需要先通过Thread类的构造方法Thread(Runnable target)构造出对象，然后调用Thread对象的start()方法来运行多线程代码。

#### Thread与Runnable的区别

- 如果一个类继承Thread，则不适合资源共享。但是如果实现了Runnable接口的话，则很容易的实现资源共享。如：

```java
class MyThread implements Runnable{
    private int ticket =5;
    @Override
    public void run(){
        for(int i=0;i<10;i++){
            try{
                Thread.sleep(500);	//睡眠0.5秒，不至于运行太快
            }catch(InterruptedException e){
                e.printStackTrace();
            }
        }
        if(this.ticket > 0){
            System.out.println("线程开始："+Thread.currentThread().getName()+"卖票："+this.ticket--);
        }
    }
}

public class TestMain(){
    public static void main(String[] args){
        MyThread mt = new MyThread();
        new Thread(mt).start();	
        //同一个mt，但是在Thread中就不可以，如果用同一个实例化对象mt，就会出现异常
        new Thread(mt).start();
        new Thread(mt).start();
        
    }
}
```

##### 实现Runnable接口比继承Thread类所具有的优势：

- 适合多个相同的程序代码的线程去处理同一个资源
- 可以避免Java中的单继承的限制
- 增加程序的健壮性，代码可以被多个线程共享，代码和数据独立
- 线程池只能放入实现Runnable或 callable 类线程，不能直接放入继承Thread的类

#### Callable

实现Callback接口

```
ExecutorService service = Executors.newSingleThreadExecutor();
Future<String> future = service.submit(new Callable(){
	@Override
	public String call() throws Exception{
		return "通过实现Callable接口";
	}
});
try{
	String result = future.get();
	System.out.println(result);
} catch (InterruptedException e) {
	e.printStackTrace();
} catch (ExecutionException e) {
	e.printStackTrace();
}
```

### 名词解释

**主线程**：JVM调用程序main()所产生的线程。
**当前线程**：一般指通过Thread.currentThread()来获取的进程。
**后台线程**：指为其他线程提供服务的线程，也称为守护线程。JVM的垃圾回收线程就是一个后台线程。用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束
**前台线程**：是指接受后台线程服务的线程。由前台线程创建的线程默认也是前台线程。可以通过isDaemon()和setDaemon()方法来判断和设置一个线程是否为后台线程。

#### 线程类的一些常用方法： 

| 方法名          | 说明                                                         |
| --------------- | ------------------------------------------------------------ |
| sleep()         | 强迫一个线程睡眠Ｎ毫秒                                       |
| isAlive()       | 判断一个线程是否存活                                         |
| join()          | 等待线程终止                                                 |
| activeCount()   | 程序中活跃的线程数                                           |
| enumerate()     | 枚举程序中的线程                                             |
| currentThread() | 得到当前线程                                                 |
| isDaemon()      | 一个线程是否为守护线程                                       |
| setDaemon()     | 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线程依赖于主线程结束而结束) |
| setName()       | 为线程设置一个名称                                           |
| wait()          | 强迫一个线程等待                                             |
| notify()        | 通知一个线程继续运行                                         |
| setPriority()   | 设置一个线程的优先级                                         |

### 线程状态

| 状态名称     | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| NEW          | 初始状态，线程被构建，但是还没有调用start()方法              |
| RUNNABLE     | 运行状态，Java线程将操作系统中的就绪和运行两种状态笼统第称作“运行中” |
| BLOCKED      | 阻塞状态，表示线程阻塞于锁                                   |
| WAITING      | 等待状态，表示线程进入等待状态，进入该状态表示当前线程需要等待其他线程做出一些特定动作（通知或中断） |
| TIME_WAITING | 超时等待状态，该状态不同于WAITING，它是可以在指定的时间自行返回的 |
| TERMINATED   | 终止状态，表示当前线程已经执行完毕                           |

新建状态：新创建一个线程对象。

就绪状态：线程对象创建后，其他线程调用了该对象的start()方法。该状态的线程位于可运行线程池中，变得可运行，等待获取CPU的使用权。

运行状态：就绪状态的线程获取了CPU，执行程序代码。

阻塞状态：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：

1. 等待阻塞：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(**wait会释放持有的锁**)
2. 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池中。
3. 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。（**sleep是不会释放持有的锁**）

死亡状态：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

#### 状态转换

![](.\png\线程状态转换图.png)

#### 线程调度

##### 线程优先级

Java线程有优先级，优先级高的线程会获得较多的运行机会。

Java线程的优先级用整数表示，取值范围是 1~10，Thread类有以下三个静态常量：

```java
static int MAX_PRIORITY
	//线程可以具有的最高优先级，取值为10
static int MIN_PRIORITY
	//线程可以具有的最低优先级，取值为1
static int NORM_PRIORITY
	//分配给线程的默认优先级，取值为5
```

Thread类的setPriority()和getPriority()方法分别用来设置和获取线程的优先级。

###### 注

- 主线程的默认优先级为Thread.NORM_PRIORITY。
- 线程的优先级有继承关系，比如A线程中创建了B线程，那么B将和A具有相同的优先级

##### interrupted

中断可以理解为线程的一个标志位，它表示了一个运行中的线程是否被其他线程进行了中断操作。其他线程可以调用该线程的interrupt()方法对其进行中断操作，同时该线程可以调用 isInterrupted（）来感知其他线程对其自身的中断操作，从而做出响应。另外，同样可以调用Thread的静态方法 interrupted（）对当前线程进行中断操作，该方法会清除中断标志位。

| 方法名                              | 详细解释                 | 备注                                                         |
| ----------------------------------- | ------------------------ | ------------------------------------------------------------ |
| public void interrupt()             | 中断该线程对象           | 如果该线程被调用了Object.wait/Object.wait(long)，或者被调用sleep(long)、join()/join(long)方法时会抛出InterruptedException并且中断标志位将会被清除 |
| public boolean isInterrupted()      | 测试该线程对象是否被中断 | 中断标志位不会被清除                                         |
| public static boolean interrupted() | 测试当前线程是否被中断   | 中断标志位会被清除                                           |

##### join

join方法可以看做是线程间协作的一种方式，很多时候，一个线程的输入可能非常依赖于另一个线程的输出。如果一个线程实例A执行了threadB.join(),其含义是：当前线程A会等待threadB线程终止后threadA才会继续执行。

| 方法                                                       |
| ---------------------------------------------------------- |
| public final synchronized void join(long millis)           |
| public final synchronized void join(long millis,int nanos) |
| public final void join() throws InterruptedException       |

join方法源码

```java
while(isAlive()){
    wait(0);
}
```

可以看出来当前等待对象threadA会一直阻塞，直到被等待对象threadB结束后即isAlive()返回false的时候才会结束while循环，当threadB退出时会调用notifyAll()方法通知所有的等待线程。

###### 示例

```java
public class JoinDemo {
    public static void main(String[] args) {
        Thread previousThread = Thread.currentThread();
        for (int i = 1; i <= 10; i++) {
            Thread curThread = new JoinThread(previousThread);
            curThread.start();
            previousThread = curThread;
        }
    }

    static class JoinThread extends Thread {
        private Thread thread;

        public JoinThread(Thread thread) {
            this.thread = thread;
        }

        @Override
        public void run() {
            try {
                thread.join();
                System.out.println(thread.getName() + " terminated.");
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

```

输出结果为

```shell
main terminated.
Thread-0 terminated.
Thread-1 terminated.
Thread-2 terminated.
Thread-3 terminated.
Thread-4 terminated.
Thread-5 terminated.
Thread-6 terminated.
Thread-7 terminated.
Thread-8 terminated.
```

创建了10个线程，每个线程都会等待前一个线程结束才会继续运行。

##### wait

线程等待。Object类中的wait()方法，导致当前的线程等待，直到其他线程调用此对象的notify() 方法或 notifyAll() 唤醒方法。这两个唤醒方法也是Object类的方法，行为等价于调用wait(0)一样。

从语法角度来说就是Obj.wait()，Obj.notify() 必须在 synchronized(Obj){...} 语句块内。

##### sleep

| 方法                                         |
| -------------------------------------------- |
| public static native void sleep(long millis) |

如果当前线程获得了锁，sleep方法并不会失去锁。

##### sleep 与wait

###### 共同点

1. 他们都是在多线程的环境下，都可以在程序的调用处阻塞指定的毫秒数，并返回

2.  wait()和sleep()都可以通过interrupt()方法 打断线程的暂停状态 ，从而使线程立刻抛出InterruptedException。 

   如果线程A希望立即结束线程B，则可以对线程B对应的Thread实例调用interrupt方法。如果此刻线程B正在wait/sleep /join，则线程B会立刻抛出InterruptedException，在catch() {} 中直接return即可安全地结束线程。

   

   **需要注意的是**，InterruptedException是线程自己从内部抛出的，并不是interrupt()方法抛出的。对某一线程调用 interrupt()时，如果该线程正在执行普通的代码，那么该线程根本就不会抛出InterruptedException。但是，一旦该线程进入到 wait()/sleep()/join()后，就会立刻抛出InterruptedException 。 

###### 区别

1. sleep()方法是Thread的静态方法，而wait是Object实例方法
2. wait()方法必须要在同步方法或者同步块中调用，也就是必须已经获得对象锁。而sleep()方法没有这个限制可以在任何地方种使用。另外，wait()方法会释放占有的对象锁，使得该线程进入等待池中，等待下一次获取资源。而sleep()方法只是会让出CPU并不会释放掉对象锁；
3. sleep()方法在休眠时间达到后如果再次获得CPU时间片就会继续执行，而wait()方法必须等待Object.notift/Object.notifyAll通知后，才会离开等待池，并且再次获得CPU时间片才会继续执行。

##### yield

| 方法名                            |
| --------------------------------- |
| public static native void yield() |

一旦执行，它会使当前线程让出CPU，但是，需要注意的是，让出的CPU并不是代表当前线程不再运行了，如果在下一次竞争中，又获得了CPU时间片当前线程依然会继续运行。另外，让出的时间片只会分配**给当前线程相同优先级**的线程。

###### yield 与 sleep的区别

同样都是当前线程会交出处理器资源，而它们不同的是，sleep()交出来的时间片其他线程**都可以去竞争**，也就是说都有机会获得当前线程让出的时间片。而yield()方法只允许与当前线程具有**相同优先级**的线程能够获得释放出来的CPU时间片。有可能在进入到可执行状态后马上又被执行。

##### notify()

线程唤醒：Object类中的notify()方法，唤醒在此对象监视器上等待的单个线程。如果所有线程都在此对象上等待，则会选择唤醒其中一个线程。**选择是任意性的**，并在对实现做出决定时发生。线程通过调用其中一个 wait 方法，在对象的监视器上等待。 直到当前的线程放弃此对象上的锁定，才能继续执行被唤醒的线程。被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争。类似的方法还有一个notifyAll()，唤醒在此对象监视器上等待的所有线程。

### 守护线程Daemon

守护线程是一种特殊的线程，就和它的名字一样，它是系统的守护者，在后台默默地守护一些系统服务，比如垃圾回收线程，JIT线程就可以理解守护线程。与之对应的就是用户线程，用户线程就可以认为是系统的工作线程，它会完成整个系统的业务操作。用户线程完全结束后就意味着整个系统的业务任务全部结束了，因此系统就没有对象需要守护的了，守护线程自然而然就会退。当一个Java应用，只有守护线程的时候，虚拟机就会自然退出。

#### 设置为守护线程

setDaemon(true);

##### 特别注意

设置守护线程要优先于 start() 方法，否则会报错

```java
Exception in thread "main" java.lang.IllegalThreadStateException
at java.lang.Thread.setDaemon(Thread.java:1365)
at learn.DaemonDemo.main(DaemonDemo.java:19)
```

#### 示例代码

```java
public class DaemonDemo {
    public static void main(String[] args) {
        Thread daemonThread = new Thread(new Runnable() {
            @Override
            public void run() {
                while (true) {
                    try {
                        System.out.println("i am alive");
                        Thread.sleep(500);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    } finally {
                        System.out.println("finally block");
                    }
                }
            }
        });
        daemonThread.setDaemon(true);
        daemonThread.start();
        //确保main线程结束前能给daemonThread能够分到时间片
        try {
            Thread.sleep(800);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}

```

输出结果

```shell
i am alive finally block i am alive
```

#### 特别注意

守护线程在退出的时候并不会执行finnaly块中的代码，所以将释放资源等操作不要放在finnaly块中执行，这种操作是不安全的

## 线程池



## 关键字

### synchronized

#### 对象锁、类锁和私有锁

见 Java锁模块中的 《锁对象、类锁、私有锁》

#### 使用场景

##### 方法

###### 实例方法

锁住的对象

​		**类的实例对象**

伪代码

```java
//实例方法，锁住的是该类的实例对象
public synchronized void method(){
    .......
}
```

###### 静态方法

锁住的对象

​		**类对象**

伪代码

```java
//静态方法，锁住的是类对象
public static synchronized void method(){
    .......
}
```

##### 代码块

###### 实例对象

锁住的对象

​		**类的实例对象**

伪代码

```java
//同步代码块，锁住的是该类的实例对象
synchronized(this){
    ......
}
```

###### class对象

锁住的对象

​		**类对象**

伪代码

```java
//同步代码块，锁住的是该类的类对象
synchronized(SynchronizedDemo.class){
    .......
}
```

###### 任意实例对象Object

锁住的对象

​		**实例对象Object**

伪代码

```java
//同步代码块，锁住的是配置的实例的对象
//String 对象作为锁
String lock ="";
synchronized(lock){
    ......
}
```

### synchronized实现原理

#### 对象锁(monitor)机制

```java
public class SynchronizedDemo{
    public static void main(String[] args){
        synchronized(SynchronizedDemo.class){
            method();
        }
    }
    private synchronized void method(){}
}
```



### volatile

#### 特性

- 可见性	对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入
- 原子性    对任意单个volatile变量的读/写具有原子性，但类似于 volatile++ 这种复合操作不具有原子性。

#### 示例

```java
class VolatileFeaturesExample{
    volatile long v1 = 0L;	//使用volatile声明64位的long型变量
    
    public void set(long l){
        v1 =1;	//单个 volatile 变量的写
    }
    
    public void getAndIncrement(){
        v1++;	//复合(多个)volatile变量的读/写
    }
    
    public long get(){
        return v1;	//单个 volatile变量的读
    }
}
```

假设有多个线程分别调用上面程序的三个方法，这个程序在语意上和下面程序等价:

```java
class VolatileFeaturesExample{
    long v1 = 0;	//64位的 long型普通变量
    
    public synchronized void set(long l){//对单个的普通变量的写用同一个监视器
        v1 = 1;
    }
    
    public void getAndIncrement(){	//普通方法调用
        long temp = get();	//调用自己同步的读方法
        temp+=1L;	//普通写操作
        set(temp);	//调用已同步的写方法
    }
    
    public synchronized long get(){
        //对单个的普通变量的读用同一个监视器同步
        return v1;
    }
}
```

对一个 volatile 变量的单个读 / 写操作，与对一个普通变量的读 / 写操作使用同一个监视器锁来同步，它们之间的执行效果相同。

监视器锁的 happens-before 规则保证释放监视器和获取监视器的两个线程之间的内存可见性，这意味着对一个 volatile 变量的读，总是能看到（任意线程）对这个 volatile 变量最后的写入。

监视器锁的语义决定了临界区代码的执行具有原子性。这意味着即使是 64 位的 long 型和 double 型变量，只要它是 volatile 变量，对该变量的读写就将具有原子性。如果是多个 volatile 操作或类似于 volatile++ 这种复合操作，这些操作整体上不具有原子性。

#### volatile 写-读建立的happens before关系

上面讲的是 volatile 变量自身的特性，对程序员来说，volatile **对线程的内存可见性的影响**比 volatile 自身的特性更为重要，也更需要我们去关注。

从 JSR-133 开始，**volatile 变量的写 - 读可以实现线程之间的通信**。

从内存语义的角度来说，volatile 与监视器锁有相同的效果：volatile 写和监视器的释放有相同的内存语义；volatile 读与监视器的获取有相同的内存语义。

##### 示例

```java
class VolatileExample{
    int a =0;
    volatile boolean flag = false;
    
    public void writer(){
        a = 1;	//1
        flag = true;	//2
    }
    
    public void reader(){
        if(flag){	//3
            int i = a;	//4
            ...
        }
    }
}
```

假设线程 A 执行 writer() 方法之后，线程 B 执行 reader() 方法。根据 happens before 规则，这个过程建立的 happens before 关系可以分为两类：

1. 根据程序次序规则：1 happens before 2; 3 happens before 4
2. 根据volatile规则， 2 happens before 3
3. 根据 happens before 的传递性规则，1 happens before 4

上述 happens before 关系的图形化表现形式如下：

![](.\png\java-volatile对线程的内存可见性.png)

在上图中，每一个箭头链接的两个节点，代表了一个 happens before 关系。黑色箭头表示程序顺序规则；橙色箭头表示 volatile 规则；蓝色箭头表示组合这些规则后提供的 happens before 保证。

这里 A 线程写一个 volatile 变量后，B 线程读同一个 volatile 变量。A 线程在写 volatile 变量之前所有可见的共享变量，在 B 线程读同一个 volatile 变量后，将立即变得对 B 线程可见。

#### volatile 写-读的内存语义

###### volatile写的内存语义

当写一个 volatile 变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。

###### volatile读的内存语义

当读一个volatile变量时，JMM会把改线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。

###### 总结

- 线程 A 写一个 volatile 变量，实质上是线程 A 向接下来将要读这个 volatile 变量的某个线程发出了（其对共享变量所在修改的）消息。
- 线程 B 读一个 volatile 变量，实质上是线程 B 接收了之前某个线程发出的（在写这个 volatile 变量之前对共享变量所做修改的）消息。
- 线程 A 写一个 volatile 变量，随后线程 B 读这个 volatile 变量，这个过程实质上是线程 A 通过主内存向线程 B 发送消息。

#### volatile内存语义的实现

为了实现 volatile 内存语义，JMM 会分别限制编译器重排序和处理器重排序。下面是 JMM 针对编译器制定的 volatile 重排序规则表：

| 是否能重排序 | 第二个操作  |             |             |
| ------------ | ----------- | ----------- | ----------- |
| 第一个操作   | 普通读 / 写 | volatile 读 | volatile 写 |
| 普通读 / 写  |             |             | NO          |
| volatile 读  | NO          | NO          | NO          |
| volatile 写  |             | NO          | NO          |

##### 总结

- 当第二个操作是 volatile 写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile 写之前的操作不会被编译器重排序到 volatile 写之后。
- 当第一个操作是 volatile 读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile 读之后的操作不会被编译器重排序到 volatile 读之前。
- 当第一个操作是 volatile 写，第二个操作是 volatile 读时，不能重排序。

#### 内存屏障

为了实现 volatile 的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能，为此，JMM 采取**保守策略**。下面是基于保守策略的 JMM 内存屏障插入策略：

- 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。
- 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。
- 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。
- 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。

##### volatile 写插入

保守策略下，volatile **写插入**内存屏障后生成的指令序列示意图：

![](.\png\java-volatile-内存屏障-保守策略.png)

上图中的 StoreStore 屏障可以保证在 volatile 写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为 StoreStore 屏障将保障上面所有的普通写在 volatile 写之前刷新到主内存。

这里比较有意思的是 volatile 写后面的 StoreLoad 屏障。这个屏障的作用是避免 volatile 写与后面可能有的 volatile 读 / 写操作重排序。因为编译器常常无法准确判断在一个 volatile 写的后面，是否需要插入一个 StoreLoad 屏障（比如，一个 volatile 写之后方法立即 return）。为了保证能正确实现 volatile 的内存语义，JMM 在这里采取了保守策略：在每个 volatile 写的后面或在每个 volatile 读的前面插入一个 StoreLoad 屏障。从整体执行效率的角度考虑，JMM 选择了在每个 volatile 写的后面插入一个 StoreLoad 屏障。因为 volatile 写 - 读内存语义的常见使用模式是：一个写线程写 volatile 变量，多个读线程读同一个 volatile 变量。当读线程的数量大大超过写线程时，选择在 volatile 写之后插入 StoreLoad 屏障将带来可观的执行效率的提升。从这里我们可以看到 JMM 在实现上的一个特点：首先确保正确性，然后再去追求执行效率。

##### volatile 读插入

在保守策略下，volatile 读插入内存屏障后生成的指令序列示意图：

![](.\png\java-volatile-读插入-保守策略.png)

上图中的 LoadLoad 屏障用来禁止处理器把上面的 volatile 读与下面的普通读重排序。LoadStore 屏障用来禁止处理器把上面的 volatile 读与下面的普通写重排序。

在实际执行时，只要不改变 volatile 写 - 读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面我们通过具体的示例代码来说明：

```java
class VolatileBarrierExample{
    int a;
    volatile int v1 =1;
    volatile int v2 = 2;
    
    void readAndWrite(){
        int i = v1;	//第一个volatile读
        int j = v2;	//第二个volatile读
        a = i + j;	//普通写
        v1 = i+j;	//第一个volatile写
        v2 = j*2;	//第二个volatile写
    }
    ....
}
```

针对 readAndWrite()方法，编译器在生成字节码时可以做如下的优化：

![](.\png\java-volatile-内存屏障-保守策略-优化.png)

注意，最后的 StoreLoad 屏障不能省略。因为第二个 volatile 写之后，方法立即 return。此时编译器可能无法准确断定后面是否会有 volatile 读或写，为了安全起见，编译器常常会在这里插入一个 StoreLoad 屏障。

上面的优化是针对任意处理器平台，由于不同的处理器有不同“松紧度”的处理器内存模型，内存屏障的插入还可以根据具体的处理器内存模型继续优化。以 x86 处理器为例，上图中除最后的 StoreLoad 屏障外，其它的屏障都会被省略。

x86 处理器仅会对写 - 读操作做重排序。X86 不会对读 - 读，读 - 写和写 - 写操作做重排序，因此在 x86 处理器中会省略掉这三种操作类型对应的内存屏障。在 x86 中，JMM 仅需在 volatile 写后面插入一个 StoreLoad 屏障即可正确实现 volatile 写 - 读的内存语义。这意味着在 x86 处理器中，volatile 写的开销比 volatile 读的开销会大很多（因为执行 StoreLoad 屏障开销会比较大）。

#### JSR-133 增强volatile的内存语义

在 JSR-133 之前的旧 Java 内存模型中，虽然不允许 volatile 变量之间重排序，但旧的 Java 内存模型允许 volatile 变量与普通变量之间重排序。在旧的内存模型中，VolatileExample 示例程序可能被重排序成下列时序来执行：

![](.\png\java-volatile-旧内存模型-重排序.png)

在旧的内存模型中，当 1 和 2 之间没有数据依赖关系时，1 和 2 之间就可能被重排序（3 和 4 类似）。其结果就是：读线程 B 执行 4 时，不一定能看到写线程 A 在执行 1 时对共享变量的修改。

因此在旧的内存模型中 ，volatile 的写 - 读没有监视器的释放 - 获取所具有的内存语义。为了提供一种比监视器锁更轻量级的线程之间通信的机制，JSR-133 专家组决定增强 volatile 的内存语义：严格限制编译器和处理器对 volatile 变量与普通变量的重排序，确保 volatile 的写 - 读和监视器的释放 - 获取一样，具有相同的内存语义。从编译器重排序规则和处理器内存屏障插入策略来看，只要 volatile 变量与普通变量之间的重排序可能会破坏 volatile 的内存语意，这种重排序就会被编译器重排序规则和处理器内存屏障插入策略禁止。

#### 使用示例

##### 状态标记量

```java
volatile boolean inited = false;
//线程1:
context = loadContext();  
inited = true;            
 
//线程2:
while(!inited ){
sleep()
}
doSomethingwithconfig(context);
```

##### double check

```java
class Singleton{
    private volatile static Singleton instance = null;

    private Singleton() {
    }

    public static Singleton getInstance() {
        if(instance==null) {
            synchronized (Singleton.class) {
                if(instance==null)
                    instance = new Singleton();
            }
        }
        return instance;
    }
}
```

#### 总结

由于 volatile 仅仅保证对单个 volatile 变量的读 / 写具有原子性，而监视器锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，监视器锁比 volatile 更强大；在可伸缩性和执行性能上，volatile 更有优势。如果读者想在程序中用 volatile 代替监视器锁，请一定谨慎。

## concurrent包的实现

由于 java 的 CAS 同时具有 volatile 读和 volatile 写的内存语义，因此 Java 线程之间的通信现在有了下面四种方式：

1. A线程写volatile变量，随后B线程读这个volatile变量
2. A线程写volatile变量，随后B线程用CAS更新这个volatile变量
3. A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量
4. A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量

Java 的 CAS 会使用现代处理器上提供的高效机器级别原子指令，这些原子指令以原子方式对内存执行读 - 改 - 写操作，这是在多处理器中实现同步的关键（从本质上来说，能够支持原子性读 - 改 - 写指令的计算机器，是顺序计算图灵机的异步等价机器，因此任何现代的多处理器都会去支持某种能对内存执行原子性读 - 改 - 写操作的原子指令）。同时，volatile 变量的读 / 写和 CAS 可以实现线程之间的通信。把这些特性整合在一起，就形成了整个 concurrent 包得以实现的基石。如果我们仔细分析 concurrent 包的源代码实现，会发现一个通用化的实现模式：

1. 首先，声明共享变量为 volatile
2. 然后，使用CAS的原子条件更新来实现线程之间的同步
3. 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信

AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic 包中的类），这些 concurrent 包中的基础类都是使用这种模式来实现的，而 concurrent 包中的高层类又是依赖于这些基础类来实现的。从整体来看，concurrent 包的实现示意图如下：

![](.\png\java-concurrent包的实现示意图.png)